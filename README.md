ğŸ§  Nietzsche-GPT

A miniature GPT-style Transformer trained from scratch on Nietzscheâ€™s writings.

This project implements a decoder-only Transformer (like GPT-2) entirely in PyTorch.
The model learns to predict the next character, allowing it to generate text in a Nietzsche-like philosophical style.

ğŸš€ Method

Build a character-level vocabulary from nietzsche.txt

Convert text â†” integers using custom encode/decode

Train a GPT block with:

Multi-Head Self-Attention

Causal masking

Feedforward MLP

Residual connections + LayerNorm

Optimize using cross-entropy and AdamW

Generate text by sampling one character at a time from model logits

ğŸ’¬ Example Output
what is truth, feelings; the false in the most great nature...

ğŸ Run

Train:

python src/train.py


Interact:

python src/interact.py

â¤ï¸ Credits

Inspired by Andrej Karpathyâ€™s nanoGPT lecture.
